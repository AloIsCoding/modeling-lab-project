{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML for Gas Adsorption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1. Only if you run this notebook on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use this notebook on Colab, please uncomment the lines below (remove the `#`) and execute the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install -U pandas-profiling[notebook]\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "#!pip install --upgrade pandas sklearn holoviews bokeh plotly matplotlib\n",
    "#!wget https://raw.githubusercontent.com/kjappelbaum/ml_molsim/2022/descriptornames.py\n",
    "#!mkdir data\n",
    "#!cd data && wget https://github.com/kjappelbaum/ml_molsim/raw/2022/data/data.csv\n",
    "#!cd data && wget https://github.com/kjappelbaum/ml_molsim/raw/2022/data/features.csv\n",
    "# import os, holoviews as hv\n",
    "# os.environ['HV_DOC_HTML'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\aloisse\\AppData\\Local\\Temp\\ipykernel_13548\\2101962328.py\", line 7, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:46\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     48\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\aloisse\\AppData\\Local\\Temp\\ipykernel_13548\\2101962328.py\", line 7, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"c:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:46\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     48\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# pandas is used to read/process data\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# machine learning dependencies\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# scaling of data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, MinMaxScaler, RobustScaler\n",
      "File \u001b[1;32mc:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[0;32m     62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aloisse\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# basics\n",
    "import os\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "# pandas is used to read/process data\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning dependencies\n",
    "# scaling of data\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# model selection\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# the KRR model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "# linear model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# pipeline to streamline modeling pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "# principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "# polynomial kernel\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "# Dummy model as baseline\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "# Variance Threshold for feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "# metrics to measure model performance\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             mean_absolute_error, mean_squared_error, max_error)\n",
    "\n",
    "# save/load models\n",
    "import joblib\n",
    "\n",
    "# For the permutation importance implementation\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from sklearn.metrics import check_scoring\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils import check_array\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pymatviz.histogram import histogram\n",
    "\n",
    "\n",
    "RANDOM_SEED = 4242424242\n",
    "DATA_DIR = 'data'\n",
    "DATA_FILE = os.path.join(DATA_DIR, 'data.csv')\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "other_descriptors = [\"CellV [A^3]\"]\n",
    "\n",
    "geometric_descriptors = [\n",
    "    \"Di\",\n",
    "    \"Df\",\n",
    "    \"Dif\",\n",
    "    \"density [g/cm^3]\",\n",
    "    \"total_SA_volumetric\",\n",
    "    \"total_SA_gravimetric\",\n",
    "    \"total_POV_volumetric\",\n",
    "    \"total_POV_gravimetric\",\n",
    "]\n",
    "\n",
    "linker_descriptors = [\n",
    "    \"f-lig-chi-0\",\n",
    "    \"f-lig-chi-1\",\n",
    "    \"f-lig-chi-2\",\n",
    "    \"f-lig-chi-3\",\n",
    "    \"f-lig-Z-0\",\n",
    "    \"f-lig-Z-1\",\n",
    "    \"f-lig-Z-2\",\n",
    "    \"f-lig-Z-3\",\n",
    "    \"f-lig-I-0\",\n",
    "    \"f-lig-I-1\",\n",
    "    \"f-lig-I-2\",\n",
    "    \"f-lig-I-3\",\n",
    "    \"f-lig-T-0\",\n",
    "    \"f-lig-T-1\",\n",
    "    \"f-lig-T-2\",\n",
    "    \"f-lig-T-3\",\n",
    "    \"f-lig-S-0\",\n",
    "    \"f-lig-S-1\",\n",
    "    \"f-lig-S-2\",\n",
    "    \"f-lig-S-3\",\n",
    "    \"lc-chi-0-all\",\n",
    "    \"lc-chi-1-all\",\n",
    "    \"lc-chi-2-all\",\n",
    "    \"lc-chi-3-all\",\n",
    "    \"lc-Z-0-all\",\n",
    "    \"lc-Z-1-all\",\n",
    "    \"lc-Z-2-all\",\n",
    "    \"lc-Z-3-all\",\n",
    "    \"lc-I-0-all\",\n",
    "    \"lc-I-1-all\",\n",
    "    \"lc-I-2-all\",\n",
    "    \"lc-I-3-all\",\n",
    "    \"lc-T-0-all\",\n",
    "    \"lc-T-1-all\",\n",
    "    \"lc-T-2-all\",\n",
    "    \"lc-T-3-all\",\n",
    "    \"lc-S-0-all\",\n",
    "    \"lc-S-1-all\",\n",
    "    \"lc-S-2-all\",\n",
    "    \"lc-S-3-all\",\n",
    "    \"lc-alpha-0-all\",\n",
    "    \"lc-alpha-1-all\",\n",
    "    \"lc-alpha-2-all\",\n",
    "    \"lc-alpha-3-all\",\n",
    "    \"D_lc-chi-0-all\",\n",
    "    \"D_lc-chi-1-all\",\n",
    "    \"D_lc-chi-2-all\",\n",
    "    \"D_lc-chi-3-all\",\n",
    "    \"D_lc-Z-0-all\",\n",
    "    \"D_lc-Z-1-all\",\n",
    "    \"D_lc-Z-2-all\",\n",
    "    \"D_lc-Z-3-all\",\n",
    "    \"D_lc-I-0-all\",\n",
    "    \"D_lc-I-1-all\",\n",
    "    \"D_lc-I-2-all\",\n",
    "    \"D_lc-I-3-all\",\n",
    "    \"D_lc-T-0-all\",\n",
    "    \"D_lc-T-1-all\",\n",
    "    \"D_lc-T-2-all\",\n",
    "    \"D_lc-T-3-all\",\n",
    "    \"D_lc-S-0-all\",\n",
    "    \"D_lc-S-1-all\",\n",
    "    \"D_lc-S-2-all\",\n",
    "    \"D_lc-S-3-all\",\n",
    "    \"D_lc-alpha-0-all\",\n",
    "    \"D_lc-alpha-1-all\",\n",
    "    \"D_lc-alpha-2-all\",\n",
    "    \"D_lc-alpha-3-all\",\n",
    "]\n",
    "\n",
    "metalcenter_descriptors = [\n",
    "    \"mc_CRY-chi-0-all\",\n",
    "    \"mc_CRY-chi-1-all\",\n",
    "    \"mc_CRY-chi-2-all\",\n",
    "    \"mc_CRY-chi-3-all\",\n",
    "    \"mc_CRY-Z-0-all\",\n",
    "    \"mc_CRY-Z-1-all\",\n",
    "    \"mc_CRY-Z-2-all\",\n",
    "    \"mc_CRY-Z-3-all\",\n",
    "    \"mc_CRY-I-0-all\",\n",
    "    \"mc_CRY-I-1-all\",\n",
    "    \"mc_CRY-I-2-all\",\n",
    "    \"mc_CRY-I-3-all\",\n",
    "    \"mc_CRY-T-0-all\",\n",
    "    \"mc_CRY-T-1-all\",\n",
    "    \"mc_CRY-T-2-all\",\n",
    "    \"mc_CRY-T-3-all\",\n",
    "    \"mc_CRY-S-0-all\",\n",
    "    \"mc_CRY-S-1-all\",\n",
    "    \"mc_CRY-S-2-all\",\n",
    "    \"mc_CRY-S-3-all\",\n",
    "    \"D_mc_CRY-chi-0-all\",\n",
    "    \"D_mc_CRY-chi-1-all\",\n",
    "    \"D_mc_CRY-chi-2-all\",\n",
    "    \"D_mc_CRY-chi-3-all\",\n",
    "    \"D_mc_CRY-Z-0-all\",\n",
    "    \"D_mc_CRY-Z-1-all\",\n",
    "    \"D_mc_CRY-Z-2-all\",\n",
    "    \"D_mc_CRY-Z-3-all\",\n",
    "    \"D_mc_CRY-I-0-all\",\n",
    "    \"D_mc_CRY-I-1-all\",\n",
    "    \"D_mc_CRY-I-2-all\",\n",
    "    \"D_mc_CRY-I-3-all\",\n",
    "    \"D_mc_CRY-T-0-all\",\n",
    "    \"D_mc_CRY-T-1-all\",\n",
    "    \"D_mc_CRY-T-2-all\",\n",
    "    \"D_mc_CRY-T-3-all\",\n",
    "    \"D_mc_CRY-S-0-all\",\n",
    "    \"D_mc_CRY-S-1-all\",\n",
    "    \"D_mc_CRY-S-2-all\",\n",
    "    \"D_mc_CRY-S-3-all\",\n",
    "]\n",
    "\n",
    "functionalgroup_descriptors = [\n",
    "    \"func-chi-0-all\",\n",
    "    \"func-chi-1-all\",\n",
    "    \"func-chi-2-all\",\n",
    "    \"func-chi-3-all\",\n",
    "    \"func-Z-0-all\",\n",
    "    \"func-Z-1-all\",\n",
    "    \"func-Z-2-all\",\n",
    "    \"func-Z-3-all\",\n",
    "    \"func-I-0-all\",\n",
    "    \"func-I-1-all\",\n",
    "    \"func-I-2-all\",\n",
    "    \"func-I-3-all\",\n",
    "    \"func-T-0-all\",\n",
    "    \"func-T-1-all\",\n",
    "    \"func-T-2-all\",\n",
    "    \"func-T-3-all\",\n",
    "    \"func-S-0-all\",\n",
    "    \"func-S-1-all\",\n",
    "    \"func-S-2-all\",\n",
    "    \"func-S-3-all\",\n",
    "    \"func-alpha-0-all\",\n",
    "    \"func-alpha-1-all\",\n",
    "    \"func-alpha-2-all\",\n",
    "    \"func-alpha-3-all\",\n",
    "    \"D_func-chi-0-all\",\n",
    "    \"D_func-chi-1-all\",\n",
    "    \"D_func-chi-2-all\",\n",
    "    \"D_func-chi-3-all\",\n",
    "    \"D_func-Z-0-all\",\n",
    "    \"D_func-Z-1-all\",\n",
    "    \"D_func-Z-2-all\",\n",
    "    \"D_func-Z-3-all\",\n",
    "    \"D_func-I-0-all\",\n",
    "    \"D_func-I-1-all\",\n",
    "    \"D_func-I-2-all\",\n",
    "    \"D_func-I-3-all\",\n",
    "    \"D_func-T-0-all\",\n",
    "    \"D_func-T-1-all\",\n",
    "    \"D_func-T-2-all\",\n",
    "    \"D_func-T-3-all\",\n",
    "    \"D_func-S-0-all\",\n",
    "    \"D_func-S-1-all\",\n",
    "    \"D_func-S-2-all\",\n",
    "    \"D_func-S-3-all\",\n",
    "    \"D_func-alpha-0-all\",\n",
    "    \"D_func-alpha-1-all\",\n",
    "    \"D_func-alpha-2-all\",\n",
    "    \"D_func-alpha-3-all\",\n",
    "]\n",
    "\n",
    "\n",
    "summed_linker_descriptors = [\n",
    "    \"sum-f-lig-chi-0\",\n",
    "    \"sum-f-lig-chi-1\",\n",
    "    \"sum-f-lig-chi-2\",\n",
    "    \"sum-f-lig-chi-3\",\n",
    "    \"sum-f-lig-Z-0\",\n",
    "    \"sum-f-lig-Z-1\",\n",
    "    \"sum-f-lig-Z-2\",\n",
    "    \"sum-f-lig-Z-3\",\n",
    "    \"sum-f-lig-I-0\",\n",
    "    \"sum-f-lig-I-1\",\n",
    "    \"sum-f-lig-I-2\",\n",
    "    \"sum-f-lig-I-3\",\n",
    "    \"sum-f-lig-T-0\",\n",
    "    \"sum-f-lig-T-1\",\n",
    "    \"sum-f-lig-T-2\",\n",
    "    \"sum-f-lig-T-3\",\n",
    "    \"sum-f-lig-S-0\",\n",
    "    \"sum-f-lig-S-1\",\n",
    "    \"sum-f-lig-S-2\",\n",
    "    \"sum-f-lig-S-3\",\n",
    "    \"sum-lc-chi-0-all\",\n",
    "    \"sum-lc-chi-1-all\",\n",
    "    \"sum-lc-chi-2-all\",\n",
    "    \"sum-lc-chi-3-all\",\n",
    "    \"sum-lc-Z-0-all\",\n",
    "    \"sum-lc-Z-1-all\",\n",
    "    \"sum-lc-Z-2-all\",\n",
    "    \"sum-lc-Z-3-all\",\n",
    "    \"sum-lc-I-0-all\",\n",
    "    \"sum-lc-I-1-all\",\n",
    "    \"sum-lc-I-2-all\",\n",
    "    \"sum-lc-I-3-all\",\n",
    "    \"sum-lc-T-0-all\",\n",
    "    \"sum-lc-T-1-all\",\n",
    "    \"sum-lc-T-2-all\",\n",
    "    \"sum-lc-T-3-all\",\n",
    "    \"sum-lc-S-0-all\",\n",
    "    \"sum-lc-S-1-all\",\n",
    "    \"sum-lc-S-2-all\",\n",
    "    \"sum-lc-S-3-all\",\n",
    "    \"sum-lc-alpha-0-all\",\n",
    "    \"sum-lc-alpha-1-all\",\n",
    "    \"sum-lc-alpha-2-all\",\n",
    "    \"sum-lc-alpha-3-all\",\n",
    "    \"sum-D_lc-chi-0-all\",\n",
    "    \"sum-D_lc-chi-1-all\",\n",
    "    \"sum-D_lc-chi-2-all\",\n",
    "    \"sum-D_lc-chi-3-all\",\n",
    "    \"sum-D_lc-Z-0-all\",\n",
    "    \"sum-D_lc-Z-1-all\",\n",
    "    \"sum-D_lc-Z-2-all\",\n",
    "    \"sum-D_lc-Z-3-all\",\n",
    "    \"sum-D_lc-I-0-all\",\n",
    "    \"sum-D_lc-I-1-all\",\n",
    "    \"sum-D_lc-I-2-all\",\n",
    "    \"sum-D_lc-I-3-all\",\n",
    "    \"sum-D_lc-T-0-all\",\n",
    "    \"sum-D_lc-T-1-all\",\n",
    "    \"sum-D_lc-T-2-all\",\n",
    "    \"sum-D_lc-T-3-all\",\n",
    "    \"sum-D_lc-S-0-all\",\n",
    "    \"sum-D_lc-S-1-all\",\n",
    "    \"sum-D_lc-S-2-all\",\n",
    "    \"sum-D_lc-S-3-all\",\n",
    "    \"sum-D_lc-alpha-0-all\",\n",
    "    \"sum-D_lc-alpha-1-all\",\n",
    "    \"sum-D_lc-alpha-2-all\",\n",
    "    \"sum-D_lc-alpha-3-all\",\n",
    "]\n",
    "\n",
    "summed_metalcenter_descriptors = [\n",
    "    \"sum-mc_CRY-chi-0-all\",\n",
    "    \"sum-mc_CRY-chi-1-all\",\n",
    "    \"sum-mc_CRY-chi-2-all\",\n",
    "    \"sum-mc_CRY-chi-3-all\",\n",
    "    \"sum-mc_CRY-Z-0-all\",\n",
    "    \"sum-mc_CRY-Z-1-all\",\n",
    "    \"sum-mc_CRY-Z-2-all\",\n",
    "    \"sum-mc_CRY-Z-3-all\",\n",
    "    \"sum-mc_CRY-I-0-all\",\n",
    "    \"sum-mc_CRY-I-1-all\",\n",
    "    \"sum-mc_CRY-I-2-all\",\n",
    "    \"sum-mc_CRY-I-3-all\",\n",
    "    \"sum-mc_CRY-T-0-all\",\n",
    "    \"sum-mc_CRY-T-1-all\",\n",
    "    \"sum-mc_CRY-T-2-all\",\n",
    "    \"sum-mc_CRY-T-3-all\",\n",
    "    \"sum-mc_CRY-S-0-all\",\n",
    "    \"sum-mc_CRY-S-1-all\",\n",
    "    \"sum-mc_CRY-S-2-all\",\n",
    "    \"sum-mc_CRY-S-3-all\",\n",
    "    \"sum-D_mc_CRY-chi-0-all\",\n",
    "    \"sum-D_mc_CRY-chi-1-all\",\n",
    "    \"sum-D_mc_CRY-chi-2-all\",\n",
    "    \"sum-D_mc_CRY-chi-3-all\",\n",
    "    \"sum-D_mc_CRY-Z-0-all\",\n",
    "    \"sum-D_mc_CRY-Z-1-all\",\n",
    "    \"sum-D_mc_CRY-Z-2-all\",\n",
    "    \"sum-D_mc_CRY-Z-3-all\",\n",
    "    \"sum-D_mc_CRY-I-0-all\",\n",
    "    \"sum-D_mc_CRY-I-1-all\",\n",
    "    \"sum-D_mc_CRY-I-2-all\",\n",
    "    \"sum-D_mc_CRY-I-3-all\",\n",
    "    \"sum-D_mc_CRY-T-0-all\",\n",
    "    \"sum-D_mc_CRY-T-1-all\",\n",
    "    \"sum-D_mc_CRY-T-2-all\",\n",
    "    \"sum-D_mc_CRY-T-3-all\",\n",
    "    \"sum-D_mc_CRY-S-0-all\",\n",
    "    \"sum-D_mc_CRY-S-1-all\",\n",
    "    \"sum-D_mc_CRY-S-2-all\",\n",
    "    \"sum-D_mc_CRY-S-3-all\",\n",
    "]\n",
    "\n",
    "summed_functionalgroup_descriptors = [\n",
    "    \"sum-func-chi-0-all\",\n",
    "    \"sum-func-chi-1-all\",\n",
    "    \"sum-func-chi-2-all\",\n",
    "    \"sum-func-chi-3-all\",\n",
    "    \"sum-func-Z-0-all\",\n",
    "    \"sum-func-Z-1-all\",\n",
    "    \"sum-func-Z-2-all\",\n",
    "    \"sum-func-Z-3-all\",\n",
    "    \"sum-func-I-0-all\",\n",
    "    \"sum-func-I-1-all\",\n",
    "    \"sum-func-I-2-all\",\n",
    "    \"sum-func-I-3-all\",\n",
    "    \"sum-func-T-0-all\",\n",
    "    \"sum-func-T-1-all\",\n",
    "    \"sum-func-T-2-all\",\n",
    "    \"sum-func-T-3-all\",\n",
    "    \"sum-func-S-0-all\",\n",
    "    \"sum-func-S-1-all\",\n",
    "    \"sum-func-S-2-all\",\n",
    "    \"sum-func-S-3-all\",\n",
    "    \"sum-func-alpha-0-all\",\n",
    "    \"sum-func-alpha-1-all\",\n",
    "    \"sum-func-alpha-2-all\",\n",
    "    \"sum-func-alpha-3-all\",\n",
    "    \"sum-D_func-chi-0-all\",\n",
    "    \"sum-D_func-chi-1-all\",\n",
    "    \"sum-D_func-chi-2-all\",\n",
    "    \"sum-D_func-chi-3-all\",\n",
    "    \"sum-D_func-Z-0-all\",\n",
    "    \"sum-D_func-Z-1-all\",\n",
    "    \"sum-D_func-Z-2-all\",\n",
    "    \"sum-D_func-Z-3-all\",\n",
    "    \"sum-D_func-I-0-all\",\n",
    "    \"sum-D_func-I-1-all\",\n",
    "    \"sum-D_func-I-2-all\",\n",
    "    \"sum-D_func-I-3-all\",\n",
    "    \"sum-D_func-T-0-all\",\n",
    "    \"sum-D_func-T-1-all\",\n",
    "    \"sum-D_func-T-2-all\",\n",
    "    \"sum-D_func-T-3-all\",\n",
    "    \"sum-D_func-S-0-all\",\n",
    "    \"sum-D_func-S-1-all\",\n",
    "    \"sum-D_func-S-2-all\",\n",
    "    \"sum-D_func-S-3-all\",\n",
    "    \"sum-D_func-alpha-0-all\",\n",
    "    \"sum-D_func-alpha-1-all\",\n",
    "    \"sum-D_func-alpha-2-all\",\n",
    "    \"sum-D_func-alpha-3-all\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short question}}$\n",
    "- We declared a global variable to fix the random seed (`RANDOM_SEED`). Why did we do this?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Answer}}$\n",
    "\n",
    "Setting a global random seed (e.g., `RANDOM_SEED = 42`) ensures reproducibility.  \n",
    "Many operations in machine learning rely on randomness — such as data shuffling, model initialization, or random sampling.\n",
    "\n",
    "If the seed is not fixed:\n",
    "- The results slightly change each time you run the code.\n",
    "- Metrics fluctuate between executions.\n",
    "- Comparing results or debugging becomes unreliable.\n",
    "\n",
    "By fixing the seed, we make sure the same code always produces identical outputs — crucial for debugging and for reproducible research.\n",
    "\n",
    "*Note:* Some GPU-based operations are still non-deterministic, but for standard scikit-learn (CPU) workflows this is sufficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on Project: Carbon-dioxide uptake in MOFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will build a model that can predict the CO$_2$ uptake of metal-organic frameworks (MOFs), which are crystalline materials consisting of inorganic metal nodes linked by organic linkers.\n",
    "\n",
    "![MOF building principle](assets/mof_building_principle.png)\n",
    "\n",
    "There are two main **learning goals** for this exercise: \n",
    "\n",
    "1. Understand the typical workflow for machine learning in materials science. We will cover exploratory data analysis (EDA) and supervised learning (KRR).\n",
    "\n",
    "2. Get familiar with some Python packages that are useful for data analysis and visualization. \n",
    "\n",
    "At the end of the exercise, you will produce an interactive plot like the one below, comparing the predictions of your model against CO$_2$ computed with GCMC simulations.\n",
    "The histograms show the distributions of the errors on the training set (left) and on the test set (right).\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"assets/result.gif\" alt=\"Parity interactive\" width=\"700\"/>\n",
    "\n",
    "This exercise requires a basic knowledge of Python, e.g. that you can write list comprehensions, and are able to read documentation of functions provided by Python packages.\n",
    "You will be asked to provide some function arguments (indicated by `#fillme` comments).\n",
    "\n",
    "You can execute all the following code cells by pressing SHIFT and ENTER and get informations about the functions by pressing TAB when you are between the parentheses (see the notes for more tips). \n",
    "\n",
    "Also the [sklearn documentation](https://scikit-learn.org/stable/user_guide.html) is a great source of reference with many explanations and examples.\n",
    "\n",
    "In pandas dataframe (df) you can select columns using their name by running `df[columnname]`. If at any point you think that the dataset is too large for your computer, you can select a subset using `df.sample()` or by making the test set larger in the train/test split (section 2). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(DATA_FILE)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first few rows to see if everythings seems reasonable ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li>Use something like <code>pd.options.display.max_columns=100</code> to adjust how many columns are shown.<code>pd.options.display.max_columns=100</code>  would show at maximum 100 columns. </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also get some basic information ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Columns: 343 entries, ASA [m^2/cm^3] to CH4LPSTP\n",
      "dtypes: float64(342), object(1)\n",
      "memory usage: 45.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short question}}$\n",
    "- How many materials are in the dataset? \n",
    "- Which datatypes do we deal with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Q2: Number of materials and datatypes overview\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m n_materials \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of materials in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_materials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m dtypes \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdtypes\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Q2: Number of materials and datatypes overview\n",
    "n_materials = df.shape[0]\n",
    "print(f\"Number of materials in the dataset: {n_materials}\\n\")\n",
    "\n",
    "dtypes = df.dtypes\n",
    "print(\"Column type counts:\")\n",
    "print(dtypes.value_counts(), \"\\n\")\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "non_numeric_cols = df.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "print(f\"Numeric columns: {len(numeric_cols)}\")\n",
    "print(f\"Non-numeric columns: {len(non_numeric_cols)}\\n\")\n",
    "\n",
    "print(\"First 10 columns and their dtypes:\")\n",
    "print(df.dtypes.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- Each row corresponds to one material.  \n",
    "- Columns represent either features (numerical descriptors of structure/chemistry) or target properties (gas uptake).  \n",
    "- Knowing datatypes is important for preprocessing:  \n",
    "  - floats/integers → usable directly  \n",
    "  - objects/strings → must be encoded or removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define three global variables (hence upper case), which are the *names* of our feature and target columns. We will use the `TARGET` for the actual regression and the `TARGET_BINARY` only for the stratified train/test split. The `FEATURES` variable is a list of column names of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"pure_uptake_CO2_298.00_1600000\"\n",
    "TARGET_BINARY = \"target_binned\"  # will be created later\n",
    "FEATURES = (\n",
    "    geometric_descriptors\n",
    "    + summed_functionalgroup_descriptors\n",
    "    + summed_linker_descriptors\n",
    "    + summed_metalcenter_descriptors\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As descriptors we will use geometric properties such as density, pore volume, etc. and [revised autocorrelation functions](https://pubs.acs.org/doi/abs/10.1021/acs.jpca.7b08750) (RACs) that have been optimized for describing inorganic compounds ([and recently adapated for MOFs](https://www.nature.com/articles/s41467-020-17755-8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples for pore geometry descriptors (in `geometric_descriptors`) include: $D_i$ (the size of the largest included sphere), $D_f$ (the largest free sphere), and $D_{if}$ (the largest included free sphere) along the pore $-$ three ways of characterizing pore size. \n",
    "\n",
    "![pore diameters](assets/spheres.png)\n",
    "\n",
    "Also included are the surface area (SA) of the pore, and the probe-occupiable pore volume (POV).\n",
    "More details on the description of pore geometries can be found in [Ongari et al.](https://pubs.acs.org/doi/abs/10.1021/acs.langmuir.7b01682)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RACs (in the lists starting with `summed_...`) operate on the structure graph and encode information about the metal center, linkers and the functional groups as differences or products of heuristics that are relevant for inorganic chemistry, such as electronegativity ($\\chi$), connectivity ($T$), identity ($I$), covalent radii ($S$), and nuclear charge ($Z$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"assets/racs.png\" alt=\"RACs scheme from the lecture\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number in the descriptornames shows the coordination shell that was considered in the calculation of the RACs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target we use for this application is the high-pressure CO$_2$ uptake. This is the amount of CO$_2$ (mmol) the MOF can load per gram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split our data into a training set and a test set.\n",
    "\n",
    "In order to prevent *any* information of the test set from leaking into our model, we split *before* starting to analyze or transform our data. For more details on why this matters, see [chapter 7.10.2 of Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn//printings/ESLII_print10.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Split with stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Stratification](https://en.wikipedia.org/wiki/Stratified_sampling) ensures that the class distributions (ratio of \"good\" to \"bad\" materials) are the same in the training and test set.\n",
    "\n",
    " $\\color{DarkBlue}{\\textsf{Short question}}$\n",
    "\n",
    "- Why is this important? What could happen if we would not do this? \n",
    " \n",
    "\n",
    "For stratification to work, we to define what makes a \"good\" or a \"bad\" material. We will use 15 mmol CO$_2$ / g as the threshold for the uptake, thus binarizing our continuous target variable. (You can choose it based on the histogram of the variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Answer}}$\n",
    "\n",
    "Stratification guarantees that the class proportions (e.g., “high” vs “low” performers)  \n",
    "remain similar in both the training and test sets.\n",
    "\n",
    "If we skip stratification:\n",
    "- The test set might not contain enough samples from one class.  \n",
    "- Metrics would become unreliable or meaningless.  \n",
    "- The model could perform well just because of data imbalance.\n",
    "\n",
    "Using `stratify=df[TARGET_BINARY]` ensures each split preserves the same class distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    " - add a column 'target_binary' that encodes whether a material is low performing (`0`) or high perfoming (`1`) by comparing the uptake with the `THRESHOLD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> you can use <a href='https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html'>pd.cut</a>, \n",
    "    <a href='https://stackoverflow.com/questions/4406389/if-else-in-a-list-comprehension'>list comprehension</a>, the <a href='https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer'> binarizer in sklearn </a>...) </li>\n",
    "    <li> a list comprehension example: <code> [1 if value > THRESHOLD else 0 for value in df[TARGET]] </code> </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = TARGET\n",
    "binary_col = TARGET_BINARY\n",
    "\n",
    "# Define threshold (default: median)\n",
    "try:\n",
    "    THRESHOLD\n",
    "except NameError:\n",
    "    THRESHOLD = df[target_col].median()\n",
    "    print(f\"No THRESHOLD defined – using median = {THRESHOLD:.3f}\")\n",
    "\n",
    "df[binary_col] = (df[target_col] > THRESHOLD).astype(int)\n",
    "\n",
    "display(df[[target_col, binary_col]].head())\n",
    "print(df[binary_col].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "We define `target_binary = 1` if the uptake exceeds the threshold,  \n",
    "and `target_binary = 0` otherwise.  \n",
    "This will later be used for stratified sampling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform the actual split into training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- select reasonable values for `XX` and `XY` and then perform the test/train splits. What do you consider when making this decision (think about what you would do with really small and really big datasets, what happens if you have only one test point, what happens to the model performance if you have more test points than training points)? \n",
    "- why do we need to perform the split into a training and test set? \n",
    "- would we use the test set to tune the hyperparameters of our model?\n",
    "\n",
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li>The `size` arguments can either be integers or, often more convenient, decimals like 0.1</li>\n",
    "    <li>When you perform the split into training and test set you need to trade-off bias (pessimistic bias due to little training data) and variance (due to little test data) </li>\n",
    "    <li>A typical split cloud be 70/30, but for huge dataset the test set might be too big and for small datasets the training set might be too small in this way </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_stratified, df_test_stratified = train_test_split(\n",
    "    df,\n",
    "    train_size=XX,\n",
    "    test_size=XY,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=df[TARGET_BINARY],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Answer}}$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Q5a ===\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size = 0.8\n",
    "test_size = 0.2\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    train_size=train_size,\n",
    "    test_size=test_size,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=df[TARGET_BINARY],\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {df_train.shape[0]}\")\n",
    "print(f\"Testing samples:  {df_test.shape[0]}\")\n",
    "print(\"\\nTrain class distribution:\")\n",
    "print(df_train[TARGET_BINARY].value_counts(normalize=True))\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(df_test[TARGET_BINARY].value_counts(normalize=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Q5b ===\n",
    "TARGET_COL = TARGET\n",
    "BINARY_COL = TARGET_BINARY\n",
    "\n",
    "FEATURES = [col for col in df.columns if col not in [TARGET_COL, BINARY_COL]]\n",
    "FEATURES = [c for c in FEATURES if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "X_train = df_train[FEATURES]\n",
    "y_train = df_train[TARGET_COL]\n",
    "X_test = df_test[FEATURES]\n",
    "y_test = df_test[TARGET_COL]\n",
    "\n",
    "print(f\"Number of features: {len(FEATURES)}\")\n",
    "print(f\"Train: {X_train.shape[0]} samples, Test: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an 80/20 split.  \n",
    "Stratification ensures both sets have similar proportions of “high” and “low” performers.  \n",
    "We must never tune hyperparameters using the test set, it should only be used for final evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data to estimate generalization :  \n",
    "how well the model performs on unseen data.  \n",
    "Without a test set, we could overfit and overestimate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we wouldn't use the test set to tune the hyperparameters\n",
    "Hyperparameter tuning uses cross-validation or a validation set.\n",
    "The test set is used only once at the end to estimate final performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory data analysis (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have put the test set aside, we can give the training set a closer look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Plot some features against the target property and calculate the Pearson and Spearman correlation coefficient (what is the different between those correlation coefficients?) \n",
    "- What are the strongest correlations? Did you expect them? \n",
    "- What can be a problem when features are correlated?\n",
    "- *Optional:* Do they change if you switch from CO$_2$ to CH$_4$ uptake as the target instead? Explain your observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the correlation matrices, you can use the `df.corr(method=)`method on your dataframe (`df`). You might want to calculate not the full correlation matrix but just the correlation of the features with the targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> To get the correlation with a target, you can use indexing. E.g. <code>df.corr(method='spearman')[TARGET]</code></li>\n",
    "    <li> use <code>.sort_values()</code> method on the output of `df.corr()` to sort by the value of the correlation coefficient  </li>\n",
    "      <li> You can use something like <code>scatter = hv.Scatter(df, 'Di', [TARGET,  'density [g/cm^3]']).opts(color='density [g/cm^3]', cmap='rainbow')</code> for plotting. Also consider the <a href=\"https://holoviews.org/reference/elements/matplotlib/Scatter.html\"> <code>holoviews</code> documentation</a>. In case <code>holoviews</code> is too new for you, you can of course just use <code>matplotlib</code> and something like <code>plt.scatter(x,y)</code> </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Answer}}$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "numeric_features = [c for c in FEATURES if pd.api.types.is_numeric_dtype(df[c])]\n",
    "corrs = df[numeric_features + [TARGET]].corr(method=\"pearson\")[TARGET].abs().sort_values(ascending=False)\n",
    "corrs = corrs.drop(labels=[TARGET], errors=\"ignore\")\n",
    "features_to_plot = corrs.index[:2].tolist() if len(corrs) >= 2 else numeric_features[:2]\n",
    "\n",
    "print(\"Selected features:\", features_to_plot)\n",
    "\n",
    "for f in features_to_plot:\n",
    "    subset = df[[f, TARGET]].dropna()\n",
    "    x, y = subset[f], subset[TARGET]\n",
    "    pearson_corr, _ = pearsonr(x, y)\n",
    "    spearman_corr, _ = spearmanr(x, y)\n",
    "\n",
    "    print(f\"\\nFeature: {f}\")\n",
    "    print(f\"  Pearson correlation:  {pearson_corr:.3f}\")\n",
    "    print(f\"  Spearman correlation: {spearman_corr:.3f}\")\n",
    "\n",
    "    sns.scatterplot(x=x, y=y)\n",
    "    plt.title(f\"{f} vs {TARGET}\\n(Pearson={pearson_corr:.3f}, Spearman={spearman_corr:.3f})\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- Pearson correlation: measures linear relationships.  \n",
    "- Spearman correlation: measures monotonic (rank-based) relationships and is less sensitive to outliers.  \n",
    "Highly correlated features can cause multicollinearity, making model coefficients unstable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strong correlations (positive or negative) reveal which features are most predictive\n",
    "of the target (gas uptake).  \n",
    "Example: larger surface area or pore size might correlate positively with uptake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly correlated features provide redundant information.  \n",
    "This can cause:\n",
    "- model instability,\n",
    "- inflated importance of variables,\n",
    "- and numerical problems in linear models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the target from CO₂ to CH₄ uptake, correlations might differ because gas–material\n",
    "interactions depend on molecular size and polarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For machine learning, it is important to have some *baselines* to which one then compares the results of a model. Think of a classification model for some rare disease where we only have 1% postives. A classification model that only predictes the negatives *all the time* will still have a amazingly high accuracy. To be able to understand if our model is really better than such a simple prediction we need to make the simple prediction first. This is what we call a baseline.\n",
    "\n",
    "A baseline could be a really simple model, a basic heuristic or the current state of the art.\n",
    "this. We will use a heuristic.\n",
    "\n",
    "For this we use sklearn `Dummy` objects that simply calculate the mean, the median or the most frequent case of the training set, when you run the `fit()` method on them (which takes the features matrix $\\mathbf{X}$ and the labels $\\mathbf{y}$ as arguments.\n",
    "This is, the prediction of a `DummyRegressor` with `mean` strategy will always be the mean, independent of the input (it will not look at the feature matrix!). \n",
    "\n",
    "Instead of using those `sklearn` objects you could also just manually compute the the mean or median of the dataset. But we will use those objects as we can learn in this way how to use estimators in `sklearn` and it is also allows you to test your full pipeline with different (baseline) models. \n",
    "What does this mean? In practice this means that you can use all the regression and classification models shown in the figure below in the same way, they will all have a `fit()` method that accepts `X` and `y` and a predict method that accepts `X` and returns the predictions. \n",
    "\n",
    "\n",
    "<img src=\"https://scikit-learn.org/1.3/_static/ml_map.png\" alt=\"ML Map\" width=\"800\"/>\n",
    "\n",
    "The estimator objects can be always used in the same way \n",
    "\n",
    "<img src=\"https://static.packt-cdn.com/products/9781789800265/graphics/d49a2e95-8f22-42ed-89f1-474b3d028787.png\" alt=\"ML Map\" width=\"400\"/>\n",
    "\n",
    "Using these objects, instead of the mean directly, allows you to easily swap them with other models in pipelines, where one chains many data transformation steps (see section 6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Build dummy models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Question}}$\n",
    "- If you call `.fit(X, y)` on a `DummyRegressor` does it actually use the `X`? If not, why is there still the place for the `X` in the function? If yes, how does it use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Answer}}$\n",
    "\n",
    "The `DummyRegressor` does not use `X`.  \n",
    "It only looks at `y` to compute a constant prediction — e.g., the mean or median of the training targets.\n",
    "\n",
    "However, the `X` parameter is still required for API consistency with all scikit-learn estimators.  \n",
    "This allows it to integrate seamlessly into pipelines, grid searches, and other tools that expect a `.fit(X, y)` method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Create [`DummyRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html) instances for  `mean`, `median`. (e.g. `dummyinstance = DummyRegressor(strategy='mean')`)\n",
    "- Train them on the training data (`dummyinstance.fit(df_train[FEATURES], df_train[TARGET])`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints</font></summary>\n",
    "<ul>\n",
    "    <li> to create <code>DummyRegressor</code> you can for example use <code> dummyregressor_mean = DummyRegressor(strategy='mean') </code> </li>\n",
    "    <li> to see the implementation of the <code>DummyRegressor</code> you can check out <a href=\"https://github.com/scikit-learn/scikit-learn/blob/73732e5a0bc9b72c7049dc699d69aaedbb70ef0a/sklearn/dummy.py#L391\"> the source code on GitHub</a> </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DummyRegressors\n",
    "dummyregressor_mean = DummyRegressor(strategy='mean')\n",
    "dummyregressor_median = DummyRegressor(#fillme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Dummy Regressors\n",
    "dummyregressor_mean.fit(df_train_stratified[FEATURES], df_train_stratified[TARGET])\n",
    "dummyregressor_median.fit(#fillme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Answer}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_mean = DummyRegressor(strategy=\"mean\")\n",
    "dummy_median = DummyRegressor(strategy=\"median\")\n",
    "\n",
    "dummy_mean.fit(X_train, y_train)\n",
    "dummy_median.fit(X_train, y_train)\n",
    "\n",
    "print(\"Dummy models trained successfully.\")\n",
    "print(\"Mean-based predictions:\", dummy_mean.predict(X_train.iloc[:3]))\n",
    "print(\"Median-based predictions:\", dummy_median.predict(X_train.iloc[:3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "- `dummy_mean` always predicts the average uptake from the training set.  \n",
    "- `dummy_median` always predicts the median uptake.\n",
    "\n",
    "They don’t learn from the features — they’re baseline models used to\n",
    "measure how well more complex models actually perform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the performance of the dummy models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Calculate maximum error, mean absolute error and mean square error for the dummy regressors on training and test set. What would you expect those numbers to be?\n",
    "- Do the actual values surprise you? \n",
    "- What does this mean in practice for reporting of metrics/the reasoning behind using baseline models\n",
    "\n",
    "It can be handy to store our metrics of choice in a nested dictionary ([Python dictionaries are key-value pairs](https://www.tutorialspoint.com/python/python_dictionary.htm)): \n",
    "\n",
    "```python\n",
    "{\n",
    "    'dummyestimator1': {\n",
    "                        'metric_a_key': metric_a_value, \n",
    "                        'metric_b_key': metric_b_value\n",
    "                    },\n",
    "    'dummyestimator2': {\n",
    "                        'metric_a_key': metric_a_value, \n",
    "                        'metric_b_key': metric_b_value\n",
    "                    },\n",
    " }\n",
    "``` \n",
    "\n",
    "You will now write functions `get_regression_metrics(model, X, y_true)` that compute the metrics and return this dictionary for a given model. The `predict` method takes the feature matrix $\\mathbf{X}$ as input.\n",
    "\n",
    "In them, we calculate \n",
    "\n",
    "$\\mathrm {MAE} =\\frac{\\sum _{i=1}^{n}\\left|Y_{i}-\\hat{y}_{i}\\right|}{n}.$\n",
    "\n",
    "and \n",
    "\n",
    "$\\mathrm {MSE} = {\\frac {1}{n}}\\sum _{i=1}^{n}(Y_{i}-{\\hat {Y_{i}}})^{2}.$ \n",
    "\n",
    "where $\\hat{y}$ are the predictions and, $Y_{i}$ the true values.\n",
    "\n",
    "as well as the maximum error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints</font></summary>\n",
    "<ul>\n",
    "    <li> to perform a prediction using a estimator object, you can call <code> classifier.predict(X) </code> </li>\n",
    "    <li> to calculate metrics, you can for example call <code>accuracy_score(true_values, predicted_values) </code> </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_metrics(model, X, y_true):\n",
    "    \"\"\"\n",
    "    Get a dicionary with regression metrics:\n",
    "\n",
    "    model: sklearn model with predict method\n",
    "    X: feature matrix\n",
    "    y_true: ground truth labels\n",
    "    \"\"\"\n",
    "    y_predicted = model.predict(#fillme)\n",
    "\n",
    "    mae = mean_absolute_error(#fillme)\n",
    "    mse = mean_squared_error(#fillme)\n",
    "    maximum_error = max_error(#fillme)\n",
    "\n",
    "    metrics_dict = {\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'max_error': maximum_error\n",
    "    }\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_regressors = [\n",
    "    ('mean', dummyregressor_mean),\n",
    "    ('median', dummyregressor_median)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_regressor_results_test = {} # initialize empty dictionary\n",
    "dummy_regressor_results_train = {}\n",
    "\n",
    "# loop over the dummy_regressor list\n",
    "# if you have a tuple regressorname, regressor = (a, b) that is automatically expanded into the variables\n",
    "# a = regressorname, b = regressor\n",
    "for regressorname, regressor in dummy_regressors:\n",
    "    print(f\"Calculating metrics for {regressorname}\")\n",
    "    dummy_regressor_results_test[regressorname] = get_regression_metrics(#fillme)\n",
    "    dummy_regressor_results_train[regressorname] = get_regression_metrics(#fillme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Answer}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, max_error\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_test = model.predict(X_test)\n",
    "\n",
    "    results = {\n",
    "        \"Train MAE\": mean_absolute_error(y_train, preds_train),\n",
    "        \"Test MAE\": mean_absolute_error(y_test, preds_test),\n",
    "        \"Train MSE\": mean_squared_error(y_train, preds_train),\n",
    "        \"Test MSE\": mean_squared_error(y_test, preds_test),\n",
    "        \"Train Max Error\": max_error(y_train, preds_train),\n",
    "        \"Test Max Error\": max_error(y_test, preds_test),\n",
    "    }\n",
    "    print(pd.DataFrame(results, index=[0]).T.rename(columns={0: \"value\"}))\n",
    "    return results\n",
    "\n",
    "print(\"Dummy (mean):\")\n",
    "evaluate_model(dummy_mean, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\nDummy (median):\")\n",
    "evaluate_model(dummy_median, X_train, y_train, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Answer}}$\n",
    "\n",
    "**What would you expect those numbers to be?**  \n",
    "- For dummy regressors (constant predictions), **MAE** will be roughly the average absolute deviation of the true targets from the chosen constant (mean or median).  \n",
    "- **MSE** will be larger than MAE in scale because squared errors penalize large deviations more strongly.  \n",
    "- **Max Error** will be the largest absolute residual in the dataset (so it depends on the extreme values / range of the target).\n",
    "\n",
    "Intuitively:\n",
    "- The mean-based dummy minimizes squared error in expectation (it returns the training mean), so MSE compared to a median-based dummy may be slightly smaller if the distribution is symmetric;  \n",
    "- The median-based dummy minimizes absolute error (MAE) in expectation, so MAE may be slightly smaller for the median dummy if the target distribution has outliers.\n",
    "\n",
    "**Do the actual values surprise you?**  \n",
    "- Usually no: constant predictors are naive, so their errors are often large compared to a model that leverages features.  \n",
    "- If the dummy errors are *very small*, this indicates either the target has very low variance (easy problem) or a data leakage / preprocessing bug (e.g., target leaked into features).  \n",
    "- If a complex model does not beat the dummy baseline, it means the model is not learning useful patterns (or there is a problem).\n",
    "\n",
    "**What does this mean in practice for reporting metrics / using baseline models?**  \n",
    "- Always report baseline performance (dummy or simple heuristic) alongside your model metrics. It provides context: raw MAE or MSE values alone are hard to interpret without a baseline.  \n",
    "- Baselines act as a sanity check: if your model cannot outperform a dummy, it is not useful.  \n",
    "- Baseline comparisons help detect issues (data leakage, incorrect targets, insufficient features) early in the workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build actual regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a simple [kernel ridge regression (KRR)](https://emtiyaz.github.io/pcml15/kernel-ridge-regression.pdf) machine learning model and train it with our raw data.\n",
    "You can try different kernels, but we recommend to start with the Gaussian radial basis function ('rbf') kernel.\n",
    " \n",
    " $\\color{DarkBlue}{\\textsf{Short Question}}$\n",
    "- Do you expect this model to perform better than the dummy models?\n",
    "- Train it and then calculate the performance metrics on the training and test set. How do they compare to the performance of the dummy models?\n",
    "- What is the shape of the Kernel and of the weights? (you can check your answer by looking at the `dual_coef_` attribute of the KRR instance. You can get shapes of objects using the `shape` atrribute "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Answer}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The new model uses a Kernel Ridge Regression with a gaussian radial basis kernel. This model is capable of capturing nonlinear relationships. Thus it would outperform the dummy models that only establishes a baseline for comparison, not for solving a real problem.\n",
    "\n",
    "- From the data we have, the Kernel model performs better than the Dummy model on the training set and showing lower errors accross all metrics. However, the Kernel model shows higher errors on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with a Gaussian kernel\n",
    "krr = KernelRidge(kernel='rbf')\n",
    "krr.fit(df_train_stratified[FEATURES], df_train_stratified[TARGET]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the metrics on the train and the test set using the get_regression_metrics functions (as above)\n",
    "\n",
    "# First we need to initialize an empty dictionary\n",
    "krr_train_metrics = {} \n",
    "krr_test_metrics = {}\n",
    "\n",
    "# Tehn we calculate metrics for training and test sets\n",
    "krr_train_metrics[\"krr\"] = get_regression_metrics(krr, df_train_stratified[FEATURES], df_train_stratified[TARGET])\n",
    "krr_test_metrics[\"krr\"] = get_regression_metrics(krr, df_test_stratified[FEATURES], df_test_stratified[TARGET])\n",
    "\n",
    "# Print the results to analyze which model performs better on the training and test sets\n",
    "print(f'Error of training set : {krr_train_metrics}')\n",
    "print(f'Error of test set : {krr_test_metrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to check the shape of the kernel matrix and the weights using the shape attribute \n",
    "\n",
    "# Shape of the kernel matrix \n",
    "kernel_matrix_shape = krr._get_kernel(df_train_stratified[FEATURES]).shape\n",
    "print(\"Shape of Kernel Matrix:\", kernel_matrix_shape)\n",
    "\n",
    "# Shape of the weights\n",
    "weights_shape = krr.dual_coef_.shape\n",
    "print(\"Shape of the weights:\", weights_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the model performance in detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have trained our first machine learning model!\n",
    "We'll first have a closer look at its performance, before learning how to improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Create a parity plot (true values against predictions)for the training and test data\n",
    "- Plot a histogram of the distribution of the training and test errors on the training and test set. Plot the errors also as a function of the true value\n",
    "- Let's assume we would like to use our model for pre-screening a library of millions of porous materials to zoom-in on those with the most promising gas uptake. Could you tolerate the errors of your model?\n",
    "- Compare the parity plots for this model with the ones for the dummy models. \n",
    "Use the plotting functions below the evaluate all the following models you train.\n",
    "\n",
    "For this exercise, it can be handy to save the results in a dictionary, e.g. \n",
    "```(python)\n",
    "res_train = {\n",
    "    'y true': [],\n",
    "    'y pred': []\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints for plotting</font></summary>\n",
    "<ul>\n",
    "    <li> If you want to use matplotlib to make the parity plots, you can use the <a href=\"https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist2d.html\">hist2d function</a> </li>\n",
    "    <li> To create the frequencies and the edges of a histogram, one can use <code>np.histogram</code></li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Answer}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries with training and test results to create parity plots\n",
    "res_train = {\n",
    "    'y true': df_train_stratified[TARGET],\n",
    "    'y pred': krr.predict(df_train_stratified[FEATURES])\n",
    "}\n",
    "\n",
    "res_test = {\n",
    "    'y true': df_test_stratified[TARGET],\n",
    "    'y pred': krr.predict(df_test_stratified[FEATURES])\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets calculate the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_train[\"error\"] = res_train[\"y true\"] - res_train[\"y pred\"]\n",
    "res_test[\"error\"] = res_test[\"y true\"] - res_test[\"y pred\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the parity plots and error distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints for plotting</font></summary>\n",
    "If you want interactive plots, you can use the following code:\n",
    "<pre><code>\n",
    "hv.extension(\"bokeh\")\n",
    "hex_train = hv.HexTiles(res_train, [\"y true\", \"y pred\"]).hist(\n",
    "    dimension=[\"y true\", \"y pred\"]\n",
    ")\n",
    "hex_test = hv.HexTiles(res_test, [\"y true\", \"y pred\"]).hist(\n",
    "    dimension=[\"y true\", \"y pred\"]\n",
    ")\n",
    "hex_train + hex_test\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the parity plot to compare true vs predicted values\n",
    "def hist_density(true_values, predicted_values, xlabel='True Values', ylabel='Density', title='Density Plot'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotting the histogram for true values\n",
    "    sns.histplot(true_values, color='blue', kde=True, label='True Values', stat='density', bins=30, alpha=0.5)\n",
    "    \n",
    "    # Plotting the histogram for predicted values\n",
    "    sns.histplot(predicted_values, color='orange', kde=True, label='Predicted Values', stat='density', bins=30, alpha=0.5)\n",
    "    \n",
    "    plt.xlabel(xlabel)  # Setting x-label\n",
    "    plt.ylabel(ylabel)  # Setting y-label\n",
    "    plt.title(title)     # Setting plot title\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # plot it\n",
    "hist_density(res_train['y true'], res_train['y pred'], xlabel='y true', ylabel='y pred', title='Density Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a figure with different subplots to compare all the data\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# First pair of subplots : Parity Plots for training and testing data\n",
    "\n",
    "#  First we need a Parity Plot for Training Data with Color Gradient based on Error\n",
    "sc1 = axs[0].scatter(res_train['y true'], res_train['y pred'], \n",
    "                     alpha=0.7, \n",
    "                     c=res_train['error'], cmap='viridis',  # Color map \n",
    "                     marker='o')  # Circle markers\n",
    "axs[0].plot([res_train['y true'].min(), res_train['y true'].max()],\n",
    "            [res_train['y true'].min(), res_train['y true'].max()],\n",
    "            color='red', linestyle='--', label='Line of Equality')\n",
    "axs[0].set_title('Parity Plot - Training Data')\n",
    "axs[0].set_xlabel('True Values')\n",
    "axs[0].set_ylabel('Predicted Values')\n",
    "axs[0].legend()\n",
    "axs[0].axis('equal')  # Ensure equal scaling\n",
    "\n",
    "# Then a Parity Plot for Testing Data with Color Gradient based on Error\n",
    "sc2 = axs[1].scatter(res_test['y true'], res_test['y pred'], \n",
    "                     alpha=0.7, \n",
    "                     c=res_test['error'], cmap='viridis',  # Color map based on 'error'\n",
    "                     marker='^')  # Triangle markers\n",
    "axs[1].plot([res_test['y true'].min(), res_test['y true'].max()],\n",
    "            [res_test['y true'].min(), res_test['y true'].max()],\n",
    "            color='red', linestyle='--', label='Line of Equality')\n",
    "axs[1].set_title('Parity Plot - Test Data')\n",
    "axs[1].set_xlabel('True Values')\n",
    "axs[1].set_ylabel('Predicted Values')\n",
    "axs[1].legend()\n",
    "axs[1].axis('equal')  # This ensure equal scaling\n",
    "\n",
    "# We need to adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "\n",
    "# Now that the first plots are done, we can do the second pair of subplots : Error Plots for training and testing data\n",
    "\n",
    "# This allows us to visualize the errors as a function of true values with color gradient\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# This is : Errors vs. True Values for Training Data with Color Gradient based on Error\n",
    "sc3 = axs[0].scatter(res_train['y true'], res_train['error'], \n",
    "                     alpha=0.7, \n",
    "                     c=res_train['error'], cmap='viridis',  # Color map based on 'error'\n",
    "                     marker='o')  # Circle markers\n",
    "axs[0].set_title('Training Errors vs. True Values')\n",
    "axs[0].set_xlabel('True Values')\n",
    "axs[0].set_ylabel('Errors')\n",
    "\n",
    "# And this :Errors vs. True Values for Testing Data with Color Gradient based on Error\n",
    "sc4 = axs[1].scatter(res_test['y true'], res_test['error'], \n",
    "                     alpha=0.7, \n",
    "                     c=res_test['error'], cmap='viridis',  # Color map based on 'error'\n",
    "                     marker='^')  # Triangle markers\n",
    "axs[1].set_title('Test Errors vs. True Values')\n",
    "axs[1].set_xlabel('True Values')\n",
    "axs[1].set_ylabel('Errors')\n",
    "\n",
    "# Again to have nice layout we adjust it and we show the plots\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the error plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Improve the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training set still has a couple of issues you might have noticed:\n",
    "- The feature values are not scaled (different features are measured in different units ...)\n",
    "- Some features are basically constant, i.e. do not contain relevant information and just increase the dimensionality of the problem \n",
    "- Some feature distributions are skewed (which is more relevant for some models than for others ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Question}}$\n",
    "- Why might the scaling of the features be relevant for a machine learning model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Standard scaling and building a first pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we will now go beyond training a single model, we will build [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), which are objects that can collect a selection of transformations and estimators. This makes it quite easy to apply the same set of operations to different datasets. A simple pipeline might be built as follows \n",
    "\n",
    "<img src=\"https://vitalflux.com/wp-content/uploads/2020/08/ML-Pipeline-Page-2-1024x307.png\" alt=\"Pipeline\" width=\"800\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Build a pipline that first performs standard scaling and then fits a KRR. Call it `pipe_w_scaling`. \n",
    "- Fit it on the training set \n",
    "- Make predictions, calculate the errors and make the parity plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints</font></summary>\n",
    "<ul>\n",
    "    <li> the <code>fit</code>, <code>predict</code> methods also work for pipelines </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_w_scaling = Pipeline(\n",
    "   [\n",
    "       ('scaling', StandardScaler()),\n",
    "       ('krr', #fillme)\n",
    "   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key component we did not optimize so far are hyperparameters. Those are parameters of the model that we usually cannot learn from the data but have to fix before we train the model. \n",
    "Since we cannot learn those parameters it is not trivial to select them. Hence, what we typically do in practice is to create another set, a \"validation set\", and use it to test models trained with different hyperparameters.\n",
    "\n",
    "The most common approach to hyperparameter optimization is to define a grid of all relevant parameters and to search over the grid for the best model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Think about which parameters you could optimize in the pipeline. Note that your KRR model has two parameters you can optimize. You can also switch off some steps by setting them to `None'.\n",
    "- For each parameter you need to define a resonable grid to search over.\n",
    "- Recall, what k-fold cross-validation does. Run the hyperparameter optimization using 5-fold cross-validation (you can adjust the number of folds according to your computational resources/impatience. It turns out at k=10 is the [best tradeoff between variance and bias](https://arxiv.org/abs/1811.12808)). \n",
    "Tune the hyperparameters until you are statisfied (e.g., until you cannot improve the cross validated error any more)\n",
    "- Why don't we use the test set for hyperparameter tuning but instead test on the validation set? \n",
    "- Evaluate the model performance by calculating the performance metrics (MAE, MSE, max error) on the training and the test set.\n",
    "- *Optional:* Instead of grid search, try to use random search on the same grid (`RandomizedSearchCV`) and fix the number of evaluations (`n_iter`) to a fraction of the number of evaluations of grid search. What do you observe and conclude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkRed}{\\textsf{Tips}}$\n",
    "- If you want to see what is happening, set the `verbosity` argument of the `GridSearchCV` object to a higher number.\n",
    " \n",
    "- If you want to speed up the optimization, you can run it in parallel by setting the `n_jobs` argument to the number of workers. If you set it to -1 it will use all available cores. *Using all cores might freeze your computer if you do not have enough memory*\n",
    " \n",
    "- If the optimization is too slow, reduce the number of data points in your set, the number of folds or the grid size. Note that it can also be a feasible strategy to first use a coarser grid and the a finer grid for fine-tuning.\n",
    "\n",
    "- For grid search, you need to define a parameter grid, which is a dictionary of the following form: \n",
    "```(python)\n",
    "param_grid = {\n",
    "                    'pipelinestage__parameter': np.logspace(-4,1,10),\n",
    "                    'pipelinestage': [None, TransformerA(), TransformerB()]\n",
    "            }\n",
    "```\n",
    "\n",
    "- After the search, you can access the best model with `.best_estimator_` and the best parameters with `.best_params_` on the GridSearchCV instance. For example `grid_krr.best_estimator_`\n",
    "\n",
    "- If you initialize the GridSearchCV instance with `refit=True` it will automatically train the model with all training data (and not only the training folds from cross-validations)\n",
    "\n",
    "The double underscore (dunder) notation works recursively and specifies the parameters for any pipeline stage. \n",
    "For example, `ovasvm__estimator__cls__C` would specifiy the `C` parameter of the estimator in the one-versus-rest classifier `ovasvm`. \n",
    "\n",
    "You can print all parameters of the pipeline using `print(sorted(pipeline.get_params().keys()))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "Be aware that tight grids will drastically increase the number of experiments you will run! In some cases, it can be useful to perform the optimization in steps, i.e., first use a coarse grid and then refine in interesting regions. \n",
    "Alternatively, there are approached like <a href=\"https://www.jmlr.org/papers/volume18/16-558/16-558.pdf\"> hyperband <a> that dynamically adjust the number of data points.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints about pipelines and grid search</font></summary>\n",
    "<ul>\n",
    "    <li> You can use the <code>np.logspace</code> function to generate a grid for values that you want to vary on a logarithmic scale </li>\n",
    "    <li> There are two hyperparameters for KRR: the regularization strength <code>alpha</code> and the Gaussian width  <code>gamma</code> </li>\n",
    "    <li> For the regularization strength, values between 1 and 1e-3 can be reasonable. For gamma you can use the median heuristic, gamma = 1 / median, or values between 1e-3 and 1e3</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid and the grid search object\n",
    "param_grid = {\n",
    "                    'scaling': [MinMaxScaler(), StandardScaler()], # test different scaling methods\n",
    "                    'krr__alpha': #fillme,\n",
    "                    'krr__#fillme': #fillme\n",
    "            }\n",
    "\n",
    "grid_krr = GridSearchCV(#your pipeline, param_grid=param_grid,\n",
    "                        cv=#number of folds, verbose=2, n_jobs=2)\n",
    "\n",
    "# optional random search\n",
    "#random_krr = RandomizedSearchCV(#your pipeline, param_distributions=param_grid, n_iter=#number of evaluations,\n",
    "#                        cv=#number of folds, verbose=2, n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the grid search by calling the fit method\n",
    "grid_krr.fit(#fillme)\n",
    "# optional random search\n",
    "# random_krr.fit(#fillme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the performance metrics\n",
    "get_regression_metrics(#fillme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for some more information about hyperparameter optimization</font></summary>\n",
    "Grid search is not the most efficient way to perform hyperparamter optimization. Even <a href=\"http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf\">random search was shown to be more efficient</a>. Really efficient though are Bayesian optimization approaches like <a href='https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf)'>TPE</a>. This is implemented in the hyperopt library, which is also installed in your conda environment.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hyperparameter optimization with hyperopt (advanded and optional outlook)</font></summary>\n",
    "    \n",
    "<b>Import the tools we need</b>\n",
    "<code>\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, mix, rand, anneal, space_eval\n",
    "from functools import partial\n",
    "</code>    \n",
    "\n",
    "<b>Define the grid</b>\n",
    "<code>\n",
    "param_hyperopt = {\n",
    "    \"krr__alpha\": hp.loguniform(\"krr__alpha\", np.log(0.001), np.log(10)),\n",
    "    \"krr__gamma\": hp.loguniform(\"krr__gamma\", np.log(0.001), np.log(10)),\n",
    "}\n",
    "</code> \n",
    "\n",
    "<b>Define the objective function</b>\n",
    "<code>\n",
    "def objective_function(params):\n",
    "    pipe.set_params(\n",
    "        **{\n",
    "            \"krr__alpha\": params[\"krr__alpha\"],\n",
    "            \"krr__gamma\": params[\"krr__gamma\"],\n",
    "        }\n",
    "    )\n",
    "    score = cross_val_score(\n",
    "        pipe, X_train, y_train, cv=10, scoring=\"neg_mean_absolute_error\"\n",
    "    ).mean()\n",
    "    return {\"loss\": -score, \"status\": STATUS_OK} \n",
    "</code>\n",
    "\n",
    "<b>We will use a search in which we mix random search, annealing and tpe</b>\n",
    "<code>\n",
    "trials = Trials()\n",
    "mix_search = partial(\n",
    "   mix.suggest,\n",
    "   p_suggest=[(0.15, rand.suggest), (0.15, anneal.suggest), (0.7, tpe.suggest)],\n",
    ")\n",
    "</code>\n",
    "\n",
    "<b>Now, we can minimize the objective function.</b>\n",
    "<code>\n",
    "best_param = fmin(\n",
    "        objective_function,\n",
    "        param_hyperopt,\n",
    "        algo=mix_search,\n",
    "        max_evals=MAX_EVALES,\n",
    "        trials=trials,\n",
    "        rstate=np.random.RandomState(RANDOM_SEED),\n",
    "    )\n",
    "</code>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we would like to remove features with low variance. This can be done by setting a variance threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Question}}$\n",
    "    \n",
    "- What is the reasoning behind doing this? \n",
    "- When might it go wrong and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:\n",
    "\n",
    "The reasonning behind removing the features with low variances under a certain threshold is that as their variation is small it can be assumed that they are no use to differentiate between different outcomes to better predict the accurate behavior according to the starting data. Removing these features simplify the model \n",
    "\n",
    "However, this resonning fails in the cases where the feature describes a rare but important event, or if the low variance is due to another feature that induces a nonlinear effect, in which case the features despite having low variation are relevant to the description of the adsorbption behavior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Add a variance threshold to the pipeline (select the correct function argument)\n",
    "- Use random search for hyperparameter optimization, retrain the pipeline, and calculate the performance metrics (max error, MAE, MSE) on the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipe_variance_threshold = Pipeline(\n",
    "    # fillme with the pipeline steps\n",
    "    [\n",
    "        ('variance_treshold', VarianceThreshold(threshold=0.5)),('scaling',StandardScaler()),('krr',KernelRidge())\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_variance_threshold = {\n",
    "                    'scaling': [None, StandardScaler()],\n",
    "                    'krr__alpha': np.logspace(-4, 1, 10),\n",
    "                    'krr__kernel': ['linear', 'rbf', 'poly'],\n",
    "                    'variance_treshold__threshold': [0.0, 1e-5, 1e-3, 0.01, 0.1, 0.5]\n",
    "            }\n",
    "\n",
    "random_variance_treshold = RandomizedSearchCV(estimator=pipe_variance_threshold, param_distributions=param_grid, n_iter=40,\n",
    "                        cv=5, verbose=2, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline and run the evaluation\n",
    "random_variance_treshold.fit(df_test_stratified[FEATURES],df_train_stratified[TARGET])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short Exercise (optional)}}$\n",
    "- replace the variance threshold with a model-based feature selection \n",
    "`('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\")))` or [any feature selection method that you would like to try](https://scikit-learn.org/stable/modules/feature_selection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we spent so much time in optimizing our model, we do not want to loose it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- use the [joblib library](https://scikit-learn.org/stable/modules/model_persistence.html) to save your model\n",
    "- make sure you can load it again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump your model\n",
    "joblib.dump(random_variance_treshold, modelRandowVarThresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load it again\n",
    "model_loaded = joblib.load(random_variance_treshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Influence of Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- what happens if you set $\\alpha$  to a really small or to large value? Why is this the case explain what the parameter means using the equation derived in the lectures?\n",
    "\n",
    " To test this, fix this value in one of your pipelines, retrain the models (re-optimizing the other hyperparameters) and rerun the performance evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:\n",
    "\n",
    "If we look back at the previous assignment and the course, one can remember that the Kernel Ridge regression corresponds to solving the following problem:\n",
    "\n",
    "$\\hat{\\alpha}= (K+\\alpha I)^{-1}y$\n",
    "\n",
    "Already from this form, it can be determine that the lower $\\alpha$ is the more importance the kernel matrix will take in the expression and vise versa. \n",
    "This can be explained by the fact that $\\alpha$ corresponds to the regularisation, the higher its value is the smoother will the model be, however, this implies that the model will be less constrainted by the data. One the other hand if $\\alpha$ is lower, the model will tend to be closer to the date resulting in a more sharp model, as the model will try to fit the data closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints</font></summary>\n",
    "<ul>\n",
    "    <li> Check the derivation for ridge regression and KRR in the notes. </li>\n",
    "    <li> Also remember the loss landscapes we discussed in the lectures about LASSO. </li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Interpreting the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that our model performs decently, we would like to know which features are mainly responsible for this, i.e. how the model performs its reasoning. \n",
    "\n",
    "One method to do so is the [permutation feature importance technique](https://christophm.github.io/interpretable-ml-book/feature-importance.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{DarkBlue}{\\textsf{Short question}}$\n",
    "\n",
    "We use both descriptors that encode the pore geometry (density, pore diameters, surface areas) as well as some that describe the chemistry of the MOF (the RACs). \n",
    "- Would you expect the relative importance of these features to be different for prediction of gas adsorption at high vs low gas pressure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for a hint</font></summary>\n",
    "<ul>\n",
    "    <li> <a href=\"https://pubs.acs.org/doi/abs/10.1021/acs.chemmater.8b02257\">An article from Diego et al.</a> (10.1021/acs.chemmater.8b02257) gives some hints.</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:\n",
    "\n",
    "The relative importance of these features does change depending on the pressure. At low pressures the adsorption process is mainly driven by chemical interaction between the adsorbant and the particules, thus chemical descriptor are more relevant. \n",
    "However, at high pressure most of the sites are occupied meaning that further adsorption can occure mainly based on remaining space rather than on chemical interaction, thus, geometry descriptors such as the one mentionned above (density, pore diameters, surface areas) are more relevant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Complete the function `_calculate_permutation_scores` (which we took from the `sklearn` package) and which is needed to calculate the permutation feature importance using the `permutation_importance` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_permutation_scores(estimator, X, y, col_idx, random_state,\n",
    "                                  n_repeats, scorer):\n",
    "    \"\"\"Calculate score when `col_idx` is permuted. Based on the sklearn implementation\n",
    "\n",
    "    estimator: sklearn estimator object\n",
    "    X: pd.Dataframe or np.array\n",
    "    y: pd.Dataframe or np.array\n",
    "    col_idx: int\n",
    "    random_state: int\n",
    "    n_repeats: int\n",
    "    scorer: function that takes model, X and y_true as arguments\n",
    "    \"\"\"\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    X_permuted = X.copy()\n",
    "    scores = np.zeros(n_repeats)\n",
    "    # get the indices\n",
    "    shuffling_idx = np.arange(X.shape[0])\n",
    "    for n_round in range(n_repeats):\n",
    "        # FILL BELOW HERE\n",
    "        # shuffle them (fill in what you want to shuffle)\n",
    "        random_state.shuffle(shuffling_idx)\n",
    "\n",
    "        # Deal with dataframes\n",
    "        if hasattr(X_permuted, \"iloc\"):\n",
    "            # .iloc selects the indices from a dataframe and you give it [row, column]\n",
    "            col = X_permuted.iloc[shuffling_idx, col_idx]\n",
    "            col.index = X_permuted.index\n",
    "            X_permuted.iloc[:, col_idx] = col\n",
    "\n",
    "        # Deal with numpy arrays\n",
    "        else:\n",
    "            # FILL BELOW HERE\n",
    "            # array indexing is [row, column]\n",
    "            X_permuted[:, col_idx] = X_permuted[shuffling_idx,col_idx]\n",
    "\n",
    "        # Get the scores\n",
    "        feature_score = scorer(estimator, X_permuted, y)\n",
    "\n",
    "        # record the scores in array\n",
    "        scores[n_round] = feature_score\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing to change in the function below, it just call the `_calculate_permutation_scores` function you just completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_importance(\n",
    "    estimator,\n",
    "    X,\n",
    "    y,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_repeats=5,\n",
    "    n_jobs=2,\n",
    "    random_state=None,\n",
    "):\n",
    "    \"\"\"Permutation importance for feature evaluation\n",
    "    estimator : object\n",
    "        An estimator that has already been :term:`fitted` and is compatible\n",
    "        with :term:`scorer`.\n",
    "    X : ndarray or DataFrame, shape (n_samples, n_features)\n",
    "        Data on which permutation importance will be computed.\n",
    "    y : array-like or None, shape (n_samples, ) or (n_samples, n_classes)\n",
    "        Targets for supervised or `None` for unsupervised.\n",
    "    scoring : string, callable or None, default=None\n",
    "        Scorer to use. It can be a single\n",
    "        string (see :ref:`scoring_parameter`) or a callable (see\n",
    "        :ref:`scoring`). If None, the estimator's default scorer is used.\n",
    "    n_repeats : int, default=5\n",
    "        Number of times to permute a feature.\n",
    "    n_jobs : int or None, default=2\n",
    "        The number of jobs to use for the computation.\n",
    "        `None` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        `-1` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "    random_state : int, RandomState instance, or None, default=None\n",
    "        Pseudo-random number generator to control the permutations of each\n",
    "        feature. See :term:`random_state`.\n",
    "    \"\"\"\n",
    "    # Deal with dataframes\n",
    "    if not hasattr(X, \"iloc\"):\n",
    "        X = check_array(X, force_all_finite=\"allow-nan\", dtype=None)\n",
    "\n",
    "    # Precompute random seed from the random state to be used\n",
    "    # to get a fresh independent RandomState instance for each\n",
    "    # parallel call to _calculate_permutation_scores, irrespective of\n",
    "    # the fact that variables are shared or not depending on the active\n",
    "    # joblib backend (sequential, thread-based or process-based).\n",
    "    random_state = check_random_state(random_state)\n",
    "    random_seed = random_state.randint(np.iinfo(np.int32).max + 1)\n",
    "\n",
    "    # Determine scorer from user options.\n",
    "    scorer = check_scoring(estimator, scoring=scoring)\n",
    "    # get the performance score on the unpermuted data\n",
    "    baseline_score = scorer(estimator, X, y)\n",
    "\n",
    "    # run the permuted evaluations in parallel for each column\n",
    "    scores = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_calculate_permutation_scores)(\n",
    "            estimator, X, y, col_idx, random_seed, n_repeats, scorer\n",
    "        )\n",
    "        for col_idx in range(X.shape[1])\n",
    "    )\n",
    "\n",
    "    # get difference two\n",
    "    importances = baseline_score - np.array(scores)\n",
    "\n",
    "    # return the results (dictionary)\n",
    "    return Bunch(\n",
    "        importances_mean=np.mean(importances, axis=1),\n",
    "        importances_std=np.std(importances, axis=1),\n",
    "        importances=importances,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\color{DarkBlue}{\\textsf{Short Exercise}}$\n",
    "- Use your function to find the five most important features.\n",
    "- Which are they? Did you expect this result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_results = permutation_importance(random_variance_treshold,df_test_stratified[FEATURES],df_train_stratified[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_results[\"features\"] = FEATURES\n",
    "bars = hv.Bars(\n",
    "    permutation_results, \"features\", [\"importances_mean\", \"importances_std\"]\n",
    ").sort(\"importances_mean\", reverse=True)\n",
    "errors = hv.ErrorBars(\n",
    "    permutation_results, \"features\", vdims=[\"importances_mean\", \"importances_std\"]\n",
    ").sort(\"importances_mean\", reverse=True)\n",
    "\n",
    "bars * errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for hints</font></summary>\n",
    "<ul>\n",
    "    <li> To get the top <emph>n</emph> indices of an array <code>a</code>, you can use <code>np.argsort(a)[-n:]</code></li>\n",
    "    <li> Get the feature names from the <code>FEATURES</code> list </li> \n",
    "    <li> combined this might look like <code>np.array(FEATURES)[np.argsort(a)[-n:]]</code></li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font color='green'>Click here for more information on model interpretation</font></summary>\n",
    "The permutation feature importance technique is not a silver bullet, e.g. there are issues with correlated features.\n",
    "However, it is likely <a href='https://explained.ai/rf-importance/'>a better choice than feature importance, like impurity decrease, derived from random forests</a>).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:\n",
    "\n",
    "the most important parameters are XX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
